{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fe26063-d961-4384-837a-e21a4ed7eb3e",
   "metadata": {},
   "source": [
    "## Section 5.2: Using SEResNet\n",
    "\n",
    "In this notebook, we are going to demonstrate using SEResNet to classify the 17 Category Flower Dataset.\n",
    "\n",
    "#### i. Configure root path\n",
    "Configure the correct root directory for the dataset folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90682f5f-c5b9-4527-bced-6635ca24eda9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/userhome/cs2/kelvin20/SEResNet\n"
     ]
    }
   ],
   "source": [
    "dataset_dir = \"./dataset/\"\n",
    "\n",
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce77d6a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: timm in /userhome/cs2/kelvin20/anaconda3/envs/project/lib/python3.7/site-packages (0.9.12)\n",
      "Requirement already satisfied: torchvision in /userhome/cs2/kelvin20/anaconda3/envs/project/lib/python3.7/site-packages (from timm) (0.8.2)\n",
      "Requirement already satisfied: pyyaml in /userhome/cs2/kelvin20/anaconda3/envs/project/lib/python3.7/site-packages (from timm) (6.0.1)\n",
      "Requirement already satisfied: huggingface-hub in /userhome/cs2/kelvin20/anaconda3/envs/project/lib/python3.7/site-packages (from timm) (0.16.4)\n",
      "Requirement already satisfied: safetensors in /userhome/cs2/kelvin20/anaconda3/envs/project/lib/python3.7/site-packages (from timm) (0.4.3)\n",
      "Requirement already satisfied: torch>=1.7 in /userhome/cs2/kelvin20/anaconda3/envs/project/lib/python3.7/site-packages (from timm) (1.7.1)\n",
      "Requirement already satisfied: typing_extensions in /userhome/cs2/kelvin20/anaconda3/envs/project/lib/python3.7/site-packages (from torch>=1.7->timm) (4.4.0)\n",
      "Requirement already satisfied: numpy in /userhome/cs2/kelvin20/anaconda3/envs/project/lib/python3.7/site-packages (from torch>=1.7->timm) (1.21.5)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /userhome/cs2/kelvin20/anaconda3/envs/project/lib/python3.7/site-packages (from huggingface-hub->timm) (4.66.2)\n",
      "Requirement already satisfied: requests in /userhome/cs2/kelvin20/anaconda3/envs/project/lib/python3.7/site-packages (from huggingface-hub->timm) (2.31.0)\n",
      "Requirement already satisfied: filelock in /userhome/cs2/kelvin20/anaconda3/envs/project/lib/python3.7/site-packages (from huggingface-hub->timm) (3.12.2)\n",
      "Requirement already satisfied: packaging>=20.9 in /userhome/cs2/kelvin20/anaconda3/envs/project/lib/python3.7/site-packages (from huggingface-hub->timm) (24.0)\n",
      "Requirement already satisfied: importlib-metadata in /userhome/cs2/kelvin20/anaconda3/envs/project/lib/python3.7/site-packages (from huggingface-hub->timm) (6.7.0)\n",
      "Requirement already satisfied: fsspec in /userhome/cs2/kelvin20/anaconda3/envs/project/lib/python3.7/site-packages (from huggingface-hub->timm) (2023.1.0)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /userhome/cs2/kelvin20/anaconda3/envs/project/lib/python3.7/site-packages (from torchvision->timm) (9.3.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /userhome/cs2/kelvin20/anaconda3/envs/project/lib/python3.7/site-packages (from importlib-metadata->huggingface-hub->timm) (3.15.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /userhome/cs2/kelvin20/anaconda3/envs/project/lib/python3.7/site-packages (from requests->huggingface-hub->timm) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /userhome/cs2/kelvin20/anaconda3/envs/project/lib/python3.7/site-packages (from requests->huggingface-hub->timm) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /userhome/cs2/kelvin20/anaconda3/envs/project/lib/python3.7/site-packages (from requests->huggingface-hub->timm) (3.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /userhome/cs2/kelvin20/anaconda3/envs/project/lib/python3.7/site-packages (from requests->huggingface-hub->timm) (3.3.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install timm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9a9607-2ae1-448e-b485-5d2cae3f77d3",
   "metadata": {},
   "source": [
    "#### 1. Load the model architecture\n",
    "For this demonstration, we will import the model architecutre from the timm library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2146a340-8e2c-43d7-8e80-4d52c5c2b5d4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/userhome/cs2/kelvin20/anaconda3/envs/project/lib/python3.7/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import timm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0507e47a-d8b9-4f04-9944-a5a7ad817bc1",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 2. Define training hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e677bc60-5cb5-4882-b5e2-e8a647bb4fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rates = [0.01, 0.001, 0.0001, 0.00005]\n",
    "batch_sizes = [16, 32, 64] \n",
    "num_epochs = [40]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64ed95f-6c83-481a-aa8d-5f2c46d0d1b3",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 3. Data transformation\n",
    "Define the dataloader and transforming function for the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eec4e414-f4d8-4b17-bcb2-28d73924928f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# define dataset class\n",
    "class FlowerDataset(ImageFolder):\n",
    "    \n",
    "    # Instanitiate dataloader\n",
    "    def __init__(self, root_dir):\n",
    "        \n",
    "        # Define the transforming function\n",
    "        transform = transforms.Compose([\n",
    "            transforms.Resize((224, 224)),  # SEResNet uses 224x224 input\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ])\n",
    "        \n",
    "        # Call parent constructor\n",
    "        super().__init__(root=root_dir, transform=transform)\n",
    "        \n",
    "    # Get data loader\n",
    "    def get_data_loader(self, batch_size, shuffle=False):\n",
    "        return DataLoader(dataset=self, batch_size=batch_size, shuffle=shuffle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f16f37d-1738-4ac4-bf3c-f421b1d47205",
   "metadata": {},
   "source": [
    "#### 4. Training\n",
    "Define the train and evaluate function for each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e76b3e82-6362-4430-be96-e968e571f97c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are using: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.nn import CrossEntropyLoss, Linear\n",
    "from torch.optim import Adam\n",
    "from datetime import datetime\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"You are using: {device}\")\n",
    "\n",
    "def train(learning_rate, batch_size, epochs):\n",
    "    \n",
    "    # Print debug log message\n",
    "    print(f\"[{datetime.now()}] Training SEResNet-50 model (learning_rate={learning_rate}, batch_size={batch_size}, epochs={epochs})\")\n",
    "    \n",
    "    # Print memory summary\n",
    "    print(f\"[{datetime.now()}] {torch.cuda.memory_summary()}\")\n",
    "    \n",
    "    # Instaniate dataset objects\n",
    "    train_dataset = FlowerDataset(dataset_dir+'/flowers/train')\n",
    "    test_dataset = FlowerDataset(dataset_dir+'/flowers/test')\n",
    "    val_dataset = FlowerDataset(dataset_dir+'/flowers/val')\n",
    "    \n",
    "    # Get dataloaders for the datasets\n",
    "    train_loader = train_dataset.get_data_loader(batch_size, shuffle=True)\n",
    "    test_loader = test_dataset.get_data_loader(batch_size)\n",
    "    val_loader = val_dataset.get_data_loader(batch_size)\n",
    "    \n",
    "    # Create model\n",
    "    model = timm.create_model('seresnet50', pretrained=False, num_classes=17).to(device)\n",
    "    \n",
    "    # Define criterion and optimizer\n",
    "    criterion = CrossEntropyLoss()\n",
    "    optimizer = Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    # Create a dictonary to record model performance\n",
    "    performance = { \"train\": [], \"test\": [], \"val\": []}\n",
    "    \n",
    "    # Evaluate accuracy for the model\n",
    "    def evaluate(model, data_loader):\n",
    "        model.eval()  # Make sure model is in evaluation mode\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in data_loader:\n",
    "                outputs = model(images.to(device))\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels.to(device)).sum().item()\n",
    "        return 100 * correct / total\n",
    "    \n",
    "    # Start training and evaluating\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        # Print debug log message\n",
    "        print(f\"[{datetime.now()}] Current epoch: {epoch + 1}\")\n",
    "        \n",
    "        model.train()\n",
    "        for inputs, labels in train_loader:\n",
    "            images = inputs.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels.to(device))\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            del outputs, loss, images\n",
    "            torch.cuda.empty_cache()\n",
    "        \n",
    "        model.eval()\n",
    "        performance['train'].append(evaluate(model, train_loader))\n",
    "        performance['test'].append(evaluate(model, test_loader))\n",
    "        performance['val'].append(evaluate(model, val_loader))\n",
    "\n",
    "        \n",
    "    # Return result\n",
    "    return performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c26c025-dafb-4f89-a346-19183d5c8cd9",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 5. Train multiple models\n",
    "Train multiple models iteratively with different defined hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "001eaca1-12a8-4297-a15a-18b6d8c4c87f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-04-22 22:00:54.491327] Training SEResNet-50 model (learning_rate=0.01, batch_size=16, epochs=40)\n",
      "[2024-04-22 22:00:54.491538] |===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n",
      "[2024-04-22 22:00:59.393262] Current epoch: 1\n",
      "[2024-04-22 22:01:38.809570] Current epoch: 2\n",
      "[2024-04-22 22:02:13.122333] Current epoch: 3\n",
      "[2024-04-22 22:02:46.495739] Current epoch: 4\n",
      "[2024-04-22 22:03:20.513586] Current epoch: 5\n",
      "[2024-04-22 22:03:54.419909] Current epoch: 6\n",
      "[2024-04-22 22:04:29.462881] Current epoch: 7\n",
      "[2024-04-22 22:05:04.856978] Current epoch: 8\n",
      "[2024-04-22 22:05:41.920056] Current epoch: 9\n",
      "[2024-04-22 22:06:17.991283] Current epoch: 10\n",
      "[2024-04-22 22:06:52.781722] Current epoch: 11\n",
      "[2024-04-22 22:07:26.802124] Current epoch: 12\n",
      "[2024-04-22 22:08:00.110718] Current epoch: 13\n",
      "[2024-04-22 22:08:32.393222] Current epoch: 14\n",
      "[2024-04-22 22:09:04.704178] Current epoch: 15\n",
      "[2024-04-22 22:09:36.994492] Current epoch: 16\n",
      "[2024-04-22 22:10:09.272192] Current epoch: 17\n",
      "[2024-04-22 22:10:41.819087] Current epoch: 18\n",
      "[2024-04-22 22:11:14.131158] Current epoch: 19\n",
      "[2024-04-22 22:11:46.701596] Current epoch: 20\n",
      "[2024-04-22 22:12:19.171016] Current epoch: 21\n",
      "[2024-04-22 22:12:51.827634] Current epoch: 22\n",
      "[2024-04-22 22:13:24.185508] Current epoch: 23\n",
      "[2024-04-22 22:13:56.495431] Current epoch: 24\n",
      "[2024-04-22 22:14:29.468190] Current epoch: 25\n",
      "[2024-04-22 22:15:01.855040] Current epoch: 26\n",
      "[2024-04-22 22:15:34.240046] Current epoch: 27\n",
      "[2024-04-22 22:16:06.680516] Current epoch: 28\n",
      "[2024-04-22 22:16:39.122869] Current epoch: 29\n",
      "[2024-04-22 22:17:11.822729] Current epoch: 30\n",
      "[2024-04-22 22:17:44.496500] Current epoch: 31\n",
      "[2024-04-22 22:18:16.753093] Current epoch: 32\n",
      "[2024-04-22 22:18:49.282368] Current epoch: 33\n",
      "[2024-04-22 22:19:21.731067] Current epoch: 34\n",
      "[2024-04-22 22:19:54.022180] Current epoch: 35\n",
      "[2024-04-22 22:20:26.480201] Current epoch: 36\n",
      "[2024-04-22 22:20:58.964617] Current epoch: 37\n",
      "[2024-04-22 22:21:31.144774] Current epoch: 38\n",
      "[2024-04-22 22:22:03.685133] Current epoch: 39\n",
      "[2024-04-22 22:22:36.073731] Current epoch: 40\n",
      "[2024-04-22 22:23:08.925632] Training SEResNet-50 model (learning_rate=0.01, batch_size=32, epochs=40)\n",
      "[2024-04-22 22:23:08.925782] |===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |       0 B  |    2103 MB |   27310 GB |   27310 GB |\n",
      "|       from large pool |       0 B  |    1993 MB |   27065 GB |   27065 GB |\n",
      "|       from small pool |       0 B  |     110 MB |     244 GB |     244 GB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |       0 B  |    2103 MB |   27310 GB |   27310 GB |\n",
      "|       from large pool |       0 B  |    1993 MB |   27065 GB |   27065 GB |\n",
      "|       from small pool |       0 B  |     110 MB |     244 GB |     244 GB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |       0 B  |    2242 MB |    4117 GB |    4117 GB |\n",
      "|       from large pool |       0 B  |    2130 MB |    4112 GB |    4112 GB |\n",
      "|       from small pool |       0 B  |     114 MB |       5 GB |       5 GB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |       0 B  |  346863 KB |   10589 GB |   10589 GB |\n",
      "|       from large pool |       0 B  |  344000 KB |   10326 GB |   10326 GB |\n",
      "|       from small pool |       0 B  |   22821 KB |     262 GB |     262 GB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |       0    |    1340    |    4999 K  |    4999 K  |\n",
      "|       from large pool |       0    |     189    |    1706 K  |    1706 K  |\n",
      "|       from small pool |       0    |    1151    |    3293 K  |    3293 K  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |       0    |    1340    |    4999 K  |    4999 K  |\n",
      "|       from large pool |       0    |     189    |    1706 K  |    1706 K  |\n",
      "|       from small pool |       0    |    1151    |    3293 K  |    3293 K  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |       0    |     132    |  133315    |  133315    |\n",
      "|       from large pool |       0    |      75    |  130539    |  130539    |\n",
      "|       from small pool |       0    |      57    |    2776    |    2776    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |       0    |     149    |    2877 K  |    2877 K  |\n",
      "|       from large pool |       0    |      46    |    1013 K  |    1013 K  |\n",
      "|       from small pool |       0    |     126    |    1863 K  |    1863 K  |\n",
      "|===========================================================================|\n",
      "\n",
      "[2024-04-22 22:23:09.511907] Current epoch: 1\n",
      "[2024-04-22 22:23:40.785691] Current epoch: 2\n",
      "[2024-04-22 22:24:12.568886] Current epoch: 3\n",
      "[2024-04-22 22:24:44.298617] Current epoch: 4\n",
      "[2024-04-22 22:25:15.365090] Current epoch: 5\n",
      "[2024-04-22 22:25:46.684598] Current epoch: 6\n",
      "[2024-04-22 22:26:17.938635] Current epoch: 7\n",
      "[2024-04-22 22:26:49.124748] Current epoch: 8\n",
      "[2024-04-22 22:27:20.214484] Current epoch: 9\n",
      "[2024-04-22 22:27:51.383088] Current epoch: 10\n",
      "[2024-04-22 22:28:22.851739] Current epoch: 11\n",
      "[2024-04-22 22:28:54.473311] Current epoch: 12\n",
      "[2024-04-22 22:29:25.905768] Current epoch: 13\n",
      "[2024-04-22 22:29:57.148304] Current epoch: 14\n",
      "[2024-04-22 22:30:28.281089] Current epoch: 15\n",
      "[2024-04-22 22:30:59.370797] Current epoch: 16\n",
      "[2024-04-22 22:31:30.326963] Current epoch: 17\n",
      "[2024-04-22 22:32:01.835567] Current epoch: 18\n",
      "[2024-04-22 22:32:32.886777] Current epoch: 19\n",
      "[2024-04-22 22:33:03.885531] Current epoch: 20\n",
      "[2024-04-22 22:33:35.224205] Current epoch: 21\n",
      "[2024-04-22 22:34:06.606061] Current epoch: 22\n",
      "[2024-04-22 22:34:37.991337] Current epoch: 23\n",
      "[2024-04-22 22:35:09.139597] Current epoch: 24\n",
      "[2024-04-22 22:35:40.311729] Current epoch: 25\n",
      "[2024-04-22 22:36:11.534445] Current epoch: 26\n",
      "[2024-04-22 22:36:42.928643] Current epoch: 27\n",
      "[2024-04-22 22:37:14.146125] Current epoch: 28\n",
      "[2024-04-22 22:37:45.139702] Current epoch: 29\n",
      "[2024-04-22 22:38:16.634062] Current epoch: 30\n",
      "[2024-04-22 22:38:47.681307] Current epoch: 31\n",
      "[2024-04-22 22:39:18.740158] Current epoch: 32\n",
      "[2024-04-22 22:39:49.924558] Current epoch: 33\n",
      "[2024-04-22 22:40:20.870267] Current epoch: 34\n",
      "[2024-04-22 22:40:51.908230] Current epoch: 35\n",
      "[2024-04-22 22:41:22.779762] Current epoch: 36\n",
      "[2024-04-22 22:41:53.700366] Current epoch: 37\n",
      "[2024-04-22 22:42:24.405160] Current epoch: 38\n",
      "[2024-04-22 22:42:55.327925] Current epoch: 39\n",
      "[2024-04-22 22:43:26.359050] Current epoch: 40\n",
      "[2024-04-22 22:43:57.374644] Training SEResNet-50 model (learning_rate=0.01, batch_size=64, epochs=40)\n",
      "[2024-04-22 22:43:57.374787] |===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |       0 B  |    3738 MB |   52493 GB |   52493 GB |\n",
      "|       from large pool |       0 B  |    3626 MB |   52113 GB |   52113 GB |\n",
      "|       from small pool |       0 B  |     112 MB |     380 GB |     380 GB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |       0 B  |    3738 MB |   52493 GB |   52493 GB |\n",
      "|       from large pool |       0 B  |    3626 MB |   52113 GB |   52113 GB |\n",
      "|       from small pool |       0 B  |     112 MB |     380 GB |     380 GB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |       0 B  |    4088 MB |    8342 GB |    8342 GB |\n",
      "|       from large pool |       0 B  |    3974 MB |    8331 GB |    8331 GB |\n",
      "|       from small pool |       0 B  |     114 MB |      10 GB |      10 GB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |       0 B  |  605047 KB |   19053 GB |   19053 GB |\n",
      "|       from large pool |       0 B  |  597120 KB |   18642 GB |   18642 GB |\n",
      "|       from small pool |       0 B  |   26056 KB |     410 GB |     410 GB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |       0    |    1340    |    7511 K  |    7511 K  |\n",
      "|       from large pool |       0    |     189    |    2566 K  |    2566 K  |\n",
      "|       from small pool |       0    |    1151    |    4945 K  |    4945 K  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |       0    |    1340    |    7511 K  |    7511 K  |\n",
      "|       from large pool |       0    |     189    |    2566 K  |    2566 K  |\n",
      "|       from small pool |       0    |    1151    |    4945 K  |    4945 K  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |       0    |     145    |  218026    |  218026    |\n",
      "|       from large pool |       0    |      88    |  212630    |  212630    |\n",
      "|       from small pool |       0    |      57    |    5396    |    5396    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |       0    |     167    |    4237 K  |    4237 K  |\n",
      "|       from large pool |       0    |      55    |    1442 K  |    1442 K  |\n",
      "|       from small pool |       0    |     126    |    2794 K  |    2794 K  |\n",
      "|===========================================================================|\n",
      "\n",
      "[2024-04-22 22:43:57.909556] Current epoch: 1\n",
      "[2024-04-22 22:44:28.576176] Current epoch: 2\n",
      "[2024-04-22 22:44:59.164812] Current epoch: 3\n",
      "[2024-04-22 22:45:29.432649] Current epoch: 4\n",
      "[2024-04-22 22:45:59.785347] Current epoch: 5\n",
      "[2024-04-22 22:46:30.133722] Current epoch: 6\n",
      "[2024-04-22 22:47:01.050381] Current epoch: 7\n",
      "[2024-04-22 22:47:31.339515] Current epoch: 8\n",
      "[2024-04-22 22:48:01.884657] Current epoch: 9\n",
      "[2024-04-22 22:48:32.108766] Current epoch: 10\n",
      "[2024-04-22 22:49:03.289158] Current epoch: 11\n",
      "[2024-04-22 22:49:33.937455] Current epoch: 12\n",
      "[2024-04-22 22:50:04.848692] Current epoch: 13\n",
      "[2024-04-22 22:50:40.691027] Current epoch: 14\n",
      "[2024-04-22 22:51:14.200877] Current epoch: 15\n",
      "[2024-04-22 22:51:49.894142] Current epoch: 16\n",
      "[2024-04-22 22:52:23.262292] Current epoch: 17\n",
      "[2024-04-22 22:52:55.616742] Current epoch: 18\n",
      "[2024-04-22 22:53:28.982597] Current epoch: 19\n",
      "[2024-04-22 22:54:02.235134] Current epoch: 20\n",
      "[2024-04-22 22:54:39.546536] Current epoch: 21\n",
      "[2024-04-22 22:55:16.249701] Current epoch: 22\n",
      "[2024-04-22 22:55:52.880597] Current epoch: 23\n",
      "[2024-04-22 22:56:31.221467] Current epoch: 24\n",
      "[2024-04-22 22:57:05.996923] Current epoch: 25\n",
      "[2024-04-22 22:57:52.212480] Current epoch: 26\n",
      "[2024-04-22 22:58:28.958424] Current epoch: 27\n",
      "[2024-04-22 22:59:01.569845] Current epoch: 28\n",
      "[2024-04-22 22:59:32.987812] Current epoch: 29\n",
      "[2024-04-22 23:00:04.168979] Current epoch: 30\n",
      "[2024-04-22 23:00:35.375386] Current epoch: 31\n",
      "[2024-04-22 23:01:05.763295] Current epoch: 32\n",
      "[2024-04-22 23:01:36.041345] Current epoch: 33\n",
      "[2024-04-22 23:02:06.744176] Current epoch: 34\n",
      "[2024-04-22 23:02:37.841663] Current epoch: 35\n",
      "[2024-04-22 23:03:09.652686] Current epoch: 36\n",
      "[2024-04-22 23:03:40.816823] Current epoch: 37\n",
      "[2024-04-22 23:04:12.198389] Current epoch: 38\n",
      "[2024-04-22 23:04:44.728759] Current epoch: 39\n",
      "[2024-04-22 23:05:16.520545] Current epoch: 40\n",
      "[2024-04-22 23:05:47.099315] Training SEResNet-50 model (learning_rate=0.001, batch_size=16, epochs=40)\n",
      "[2024-04-22 23:05:47.099768] |===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |       0 B  |    7028 MB |   76832 GB |   76832 GB |\n",
      "|       from large pool |       0 B  |    6912 MB |   76371 GB |   76371 GB |\n",
      "|       from small pool |       0 B  |     116 MB |     461 GB |     461 GB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |       0 B  |    7028 MB |   76832 GB |   76832 GB |\n",
      "|       from large pool |       0 B  |    6912 MB |   76371 GB |   76371 GB |\n",
      "|       from small pool |       0 B  |     116 MB |     461 GB |     461 GB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |       0 B  |    8164 MB |   12943 GB |   12943 GB |\n",
      "|       from large pool |       0 B  |    8046 MB |   12928 GB |   12928 GB |\n",
      "|       from small pool |       0 B  |     118 MB |      15 GB |      15 GB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |       0 B  |     870 MB |   27483 GB |   27483 GB |\n",
      "|       from large pool |       0 B  |     863 MB |   26984 GB |   26984 GB |\n",
      "|       from small pool |       0 B  |      25 MB |     499 GB |     499 GB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |       0    |    1340    |    8779 K  |    8779 K  |\n",
      "|       from large pool |       0    |     189    |    3001 K  |    3001 K  |\n",
      "|       from small pool |       0    |    1151    |    5778 K  |    5778 K  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |       0    |    1340    |    8779 K  |    8779 K  |\n",
      "|       from large pool |       0    |     189    |    3001 K  |    3001 K  |\n",
      "|       from small pool |       0    |    1151    |    5778 K  |    5778 K  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |       0    |     156    |  272808    |  272808    |\n",
      "|       from large pool |       0    |      97    |  264911    |  264911    |\n",
      "|       from small pool |       0    |      59    |    7897    |    7897    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |       0    |     167    |    4864 K  |    4864 K  |\n",
      "|       from large pool |       0    |      55    |    1603 K  |    1603 K  |\n",
      "|       from small pool |       0    |     129    |    3261 K  |    3261 K  |\n",
      "|===========================================================================|\n",
      "\n",
      "[2024-04-22 23:05:47.687594] Current epoch: 1\n",
      "[2024-04-22 23:06:21.471178] Current epoch: 2\n",
      "[2024-04-22 23:06:55.281189] Current epoch: 3\n"
     ]
    }
   ],
   "source": [
    "# Use to store result\n",
    "performances = dict()\n",
    "\n",
    "def train_models(learning_rates, batch_sizes, num_epochs):\n",
    "    # Evaluating models with respect to different hyperparameters\n",
    "    for learning_rate in learning_rates:\n",
    "        for batch_size in batch_sizes:\n",
    "            for epochs in num_epochs:\n",
    "                performances[(learning_rate, batch_size, epochs)] = train(learning_rate, batch_size, epochs)\n",
    "                torch.cuda.empty_cache()\n",
    "                \n",
    "train_models(learning_rates, batch_sizes, num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae665f54-e7ae-4903-a5e9-5b273d7055db",
   "metadata": {},
   "source": [
    "#### 6. Model Evaluations\n",
    "First, we plot training, testing, and validation accuracies against number of epochs for individual models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254003e2-0b89-427e-8165-4bf91dbd5a35",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "for model_hyperparams in performances.keys():\n",
    "    \n",
    "    # Destructure model hyperparameters from dictonary keys\n",
    "    learning_rate, batch_size, epochs = model_hyperparams\n",
    "    \n",
    "    # Plot accuracies for different datasets\n",
    "    for label in [\"train\", \"test\", \"val\"]:\n",
    "        plt.plot([x + 1 for x in range(epochs)], performances[model_hyperparams][label], label=label)\n",
    "    \n",
    "    # Show plot\n",
    "    plt.title(f\"SEResNet Top-1 Accuracies on 17 Flowers Dataset (learning rate={learning_rate}, batch size={batch_size})\")\n",
    "    plt.xlabel(\"Number of Epoch\")\n",
    "    plt.ylabel(\"Top-1 Accuracy\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93d08d3-e7b4-48f3-9c7a-dcd4c4bfc341",
   "metadata": {},
   "source": [
    "Then, we plot testing accuracies against number of epochs for models with the same learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0328768-3ed2-43d4-9089-3c850f00159a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for target_learning_rate in learning_rates:\n",
    "    \n",
    "    for model_hyperparams in performances.keys():\n",
    "    \n",
    "        # Destructure model hyperparameters from dictonary keys\n",
    "        learning_rate, batch_size, epochs = model_hyperparams\n",
    "        \n",
    "        if (learning_rate != target_learning_rate):\n",
    "            continue\n",
    "        \n",
    "        plt.plot([x + 1 for x in range(epochs)], performances[model_hyperparams][\"test\"], label=f\"batch_size={batch_size}\")\n",
    "        \n",
    "    # Show plot\n",
    "    plt.title(f\"SEResNet Top-1 Accuracies on 17 Flowers (Test) Dataset (learning rate={target_learning_rate})\")\n",
    "    plt.xlabel(\"Number of Epoch\")\n",
    "    plt.ylabel(\"Top-1 Accuracy\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505b3043-7391-487e-8af6-81bf74ec58e4",
   "metadata": {},
   "source": [
    "Finally, we plot testing accuracies against number of epochs for models with the same batch size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a6c07a-2366-4498-abc5-724f3eff70d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for target_batch_size in batch_sizes:\n",
    "    \n",
    "    for model_hyperparams in performances.keys():\n",
    "    \n",
    "        # Destructure model hyperparameters from dictonary keys\n",
    "        learning_rate, batch_size, epochs = model_hyperparams\n",
    "        \n",
    "        if (batch_size != target_batch_size):\n",
    "            continue\n",
    "        \n",
    "        plt.plot([x + 1 for x in range(epochs)], performances[model_hyperparams][\"test\"], label=f\"learning_rate={learning_rate}\")\n",
    "        \n",
    "    # Show plot\n",
    "    plt.title(f\"SEResNet Top-1 Accuracies on 17 Flowers (Test) Dataset (batch_size={batch_size})\")\n",
    "    plt.xlabel(\"Number of Epoch\")\n",
    "    plt.ylabel(\"Top-1 Accuracy\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e196244d-3d10-4524-8c59-3441672a30a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
